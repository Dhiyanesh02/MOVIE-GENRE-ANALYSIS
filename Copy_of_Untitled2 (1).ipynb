{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# FINAL MODULE\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import nltk\n",
        "\n",
        "# Ensure you have downloaded the necessary NLTK data files\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the training dataset\n",
        "data = pd.read_csv('/content/kaggle_movie_train.csv')  # Adjust the path to your training dataset\n",
        "\n",
        "# Print column names to verify if 'synopsis' and 'genre' exist\n",
        "print(\"Column names in the training dataset:\", data.columns)\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):  # Ensure the input is a string\n",
        "        text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "        text = text.lower()  # Convert to lowercase\n",
        "        tokens = text.split()  # Tokenize\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]  # Lemmatize and remove stopwords\n",
        "        return ' '.join(tokens)\n",
        "    return ''\n",
        "\n",
        "# Ensure the necessary columns are present in the training data\n",
        "if 'text' not in data.columns or 'genre' not in data.columns:\n",
        "    raise ValueError(\"The training dataset must contain 'text' and 'genre' columns.\")\n",
        "\n",
        "# Apply preprocessing to the 'synopsis' column\n",
        "data['cleaned_text'] = data['genre'].apply(preprocess_text)\n",
        "\n",
        "# Display the first few rows to verify preprocessing\n",
        "print(data[['genre', 'cleaned_text']].head())\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Adjust the number of features as needed\n",
        "X = tfidf.fit_transform(data['genre']).toarray()\n",
        "\n",
        "# The target variable (genre)\n",
        "y = data['genre']\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Number of classes:\", len(set(y)))\n",
        "\n",
        "# Initialize the Multinomial Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# --- Prediction on test data from CSV file ---\n",
        "\n",
        "# Load the test data CSV file\n",
        "test_data = pd.read_csv('/content/kaggle_movie_test.csv')  # Adjust the path to your test dataset\n",
        "\n",
        "# Check if 'synopsis' column exists in the test dataset\n",
        "if 'text' not in test_data.columns:\n",
        "    raise ValueError(\"The test dataset must contain a 'text' column.\")\n",
        "\n",
        "# Preprocess the test data\n",
        "test_data['cleaned_text'] = test_data['text'].apply(preprocess_text)\n",
        "\n",
        "# Transform the cleaned test data using the same TF-IDF vectorizer\n",
        "X_test_new = tfidf.transform(test_data['cleaned_text']).toarray()\n",
        "\n",
        "# Make predictions using the trained model\n",
        "test_data['predicted_genre'] = model.predict(X_test_new)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Predictions for the test data:\")\n",
        "print(test_data[['text', 'predicted_genre']])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00KYj6nj43S6",
        "outputId": "ff8413bf-7ea2-4ef7-b117-36ec742e8408"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in the training dataset: Index(['id', 'text', 'genre'], dtype='object')\n",
            "      genre cleaned_text\n",
            "0  thriller     thriller\n",
            "1    comedy       comedy\n",
            "2     drama        drama\n",
            "3  thriller     thriller\n",
            "4     drama        drama\n",
            "Shape of X_train: (18063, 10)\n",
            "Shape of X_test: (4516, 10)\n",
            "Number of classes: 9\n",
            "Accuracy: 100.00%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      action       1.00      1.00      1.00       473\n",
            "   adventure       1.00      1.00      1.00        25\n",
            "      comedy       1.00      1.00      1.00       635\n",
            "       drama       1.00      1.00      1.00      1728\n",
            "      horror       1.00      1.00      1.00        84\n",
            "       other       1.00      1.00      1.00        66\n",
            "     romance       1.00      1.00      1.00        12\n",
            "      sci-fi       1.00      1.00      1.00       106\n",
            "    thriller       1.00      1.00      1.00      1387\n",
            "\n",
            "    accuracy                           1.00      4516\n",
            "   macro avg       1.00      1.00      1.00      4516\n",
            "weighted avg       1.00      1.00      1.00      4516\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 473    0    0    0    0    0    0    0    0]\n",
            " [   0   25    0    0    0    0    0    0    0]\n",
            " [   0    0  635    0    0    0    0    0    0]\n",
            " [   0    0    0 1728    0    0    0    0    0]\n",
            " [   0    0    0    0   84    0    0    0    0]\n",
            " [   0    0    0    0    0   66    0    0    0]\n",
            " [   0    0    0    0    0    0   12    0    0]\n",
            " [   0    0    0    0    0    0    0  106    0]\n",
            " [   0    0    0    0    0    0    0    0 1387]]\n",
            "Predictions for the test data:\n",
            "                                                   text predicted_genre\n",
            "0      glances at her. BOOK Maybe I ought to learn t...           drama\n",
            "1     hout breaking stride. Tatiana sees her and can...           drama\n",
            "2     dead bodies. GEORDI Mitchell... DePaul... LANG...           drama\n",
            "3      take myself. BRANDON How bad is the other thi...           drama\n",
            "4     her body to shield his own. KAY Freeze it, Bug...           drama\n",
            "...                                                 ...             ...\n",
            "5584   Crazy Love script by Carol Watson COMMITTED f...           drama\n",
            "5585   break? You folks don't need a break, you need...           drama\n",
            "5586  egain control of his battered psyche. LIVIA Ca...           drama\n",
            "5587  t BEN GRIMM. A normal man. He smiles wide, sha...           drama\n",
            "5588  and sees that the elevator is in use and the s...           drama\n",
            "\n",
            "[5589 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEGK2d-f0Pt1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}